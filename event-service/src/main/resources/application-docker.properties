spring.application.name=event-service
event-service.version=v1.0

server.port=8084

#mongodb connection
spring.data.mongodb.host=mongodb
spring.data.mongodb.port=27017
spring.data.mongodb.database=event-service
spring.data.mongodb.username=admin
spring.data.mongodb.password=password
spring.data.mongodb.authentication-database=admin

booking.service.url=http://booking-service:8082
user.service.url=http://user-service:8083

springdoc.swagger-ui.path=/swagger-ui
springdoc.api-docs.path=/api-docs


#kafka properties - stores event as json, then deserialize to use again
spring.kafka.bootstrap-servers=broker:29092
#spring.kafka.template.default-topic=order-placed
spring.kafka.consumer.group-id=eventService
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#serializer class for serializing kafka
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
#to orderplaced event-packageing file path
spring.kafka.consumer.properties.spring.json.type.mapping=event:ca.gbc.eventservice.event.BookingMadeEvent

#spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
#spring.kafka.consumer.properties.spring.deserializer.key.delegate.class=org.apache.kafka.common.serialization.SpringDeserializer
#spring.kafka.consumer.properties.spring.deserializer.value.delegate.class=org.confluent.kafka.serializers.KafkaAvro.Deserializer

#spring.kafka.consumer.properties.schema.url=http://localhost:8087
#spring.kafka.consumer.properties.specific.avro.reader=true
#not solely on event occurred, but all that haven't been processed yet
spring.kafka.consumer.auto-offset-reset=earliest

spring.mail.host=sandbox.smtp.mailtrap.io
spring.mail.port=2525
spring.mail.username=839ad39e12296d
spring.mail.password=42c4f4c49bd86e

